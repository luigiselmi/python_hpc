Ch.8 Concurrency
================
Concurrency is implemented in CPUs to better use its resources in performing I/O operations such as reading or writing to a file or socket. Concurrency means performing several tasks using only one CPu and one thread of execution. It differs from parallel processing in which tasks are distributed to more than one threads and cores. A thread can perform multiple tasks concurrently with asynchronous function calls. The asynchronous call returns immediately and the thread can continue without waiting for the function call to complete. An asynchronous function can be passed as an argument to a function to perform a task while it is running without stopping to wait for it. These type of functions are called *callback*. For example a function that fits some data points to a model might use a callback function to save the best model at each iteration. When we execute an application the operating system start a process, and at least one thread of execution, and assigns a core and memory space to it. Python provides three modules for concurrency ([asyncio](https://docs.python.org/3/library/asyncio.html)), multithreading ([threading](https://docs.python.org/3/library/threading.html)), and [multiprocessing](https://docs.python.org/3/library/multiprocessing.html). 

## Synchronous tasks
In this chapter we start from an example of synchronous call between an http server and a client. The client will send several http requests to the server, using the same port, with a delay parameter that will tell the server how long the connection should last. An http request is synchronous, meaning that the client has to wait for the server to release the connection before moving on. Since the server is single threaded, that is it can use only one core, it can only process one request at a time. All the requests are sent in a loop and the execution time depend on the server's latency. We will see that the total time to complete all the requests will be close to the sum of the time needed to complete each one. This means that the (synchronous) requests are processed sequentially, not concurrently. In following examples we will use some Python packages that will allow us to send asynchronous request to the server.   

## Asynchronous tasks
Concurrency can be achieved in three ways: 1) time slicing, 2) multithreading, 3) multiprocessing. Time slicing uses only one core and one thread and it's the easiest way to concurrency in Python. Concurrency can be used in I/O-bound or CPU-bound tasks as it allows a program to proceed without waiting for those resources being available. Python implements the Global Interpreter Lock and forbids CPU-bound tasks to more than one process or thread, indipendently from the availability of more cores. I/O-bound tasks can be executed concurrently. A common I/O-bound task is the socket communication, for example between a server and a client using the http protocol. A socket is where the a client sends a message to the server and receives its response. A scoket can work on blocking mode, that is synchronously, or non-blocking mode, that is asynchronously. In blocking mode a socket does not returns till the task is completed. In non-blocking mode the socket returns immediately after receiving a request and a task is created and put in a queue to be executed as long as there are no further I/O request. 

## References
* [Fowler - Python Concurrency with asyncio](https://www.manning.com/books/python-concurrency-with-asyncio)

