Ch.8 Concurrency
================
Concurrency is implemented in CPUs to better use its resources in performing I/O operations such as reading or writing to a file or socket. Concurrency means performing several tasks using only one CPu and one thread of execution. It differs from parallel processing in which tasks are distributed to more than one threads and cores. A thread can perform multiple tasks concurrently with asynchronous function calls. The asynchronous call returns immediately and the thread can continue without waiting for the function call to complete. An asynchronous function can be passed as an argument to a function to perform a task while it is running without stopping to wait for it. These type of functions are called *callback*. For example a function that fits some data points to a model might use a callback function to save the best model at each iteration. 

## Synchronous communication
In this chapter we start from an example of synchronous call between an http server and a client. The client will send several http requests to the server with a delay parameter that will tell the server how long the connection should last. An http request is synchronous, meaning that the client has to wait for the server to release the connection before moving on. We will see that the total time to complete all the requests will be close to the sum of the time needed to complete each one. In following example we will use some Python packages that will allow us to send asynchronous request to the server.   